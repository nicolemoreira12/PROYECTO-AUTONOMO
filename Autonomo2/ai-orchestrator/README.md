# ğŸ¤– AI Orchestrator - Microservicio de OrquestaciÃ³n de IA

Microservicio que orquesta las interacciones con modelos de lenguaje (LLM) para crear un asistente conversacional multimodal con herramientas MCP (Model Context Protocol).

## ğŸ“‹ CaracterÃ­sticas

- âœ… **OrquestaciÃ³n de IA**: Coordina la interacciÃ³n con mÃºltiples proveedores de LLM
- âœ… **Multimodal**: Procesa texto, imÃ¡genes, PDFs y audio
- âœ… **MCP Tools**: Ejecuta acciones de negocio mediante herramientas
- âœ… **GestiÃ³n de Contexto**: Mantiene el historial de conversaciÃ³n en Redis
- âœ… **WebSocket**: Chat en tiempo real con Socket.io
- âœ… **PatrÃ³n Strategy**: Intercambio dinÃ¡mico de proveedores LLM
- âœ… **RESTful API**: Endpoints HTTP para integraciÃ³n

## ğŸ—ï¸ Arquitectura

```
ai-orchestrator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ adapters/          # LLM Adapters (Gemini, OpenAI, Claude)
â”‚   â”œâ”€â”€ tools/             # MCP Tools (consultas, acciones, reportes)
â”‚   â”œâ”€â”€ services/          # LÃ³gica de negocio
â”‚   â”‚   â””â”€â”€ orchestrator.service.ts
â”‚   â”œâ”€â”€ controllers/       # Controladores HTTP
â”‚   â”œâ”€â”€ routes/            # DefiniciÃ³n de rutas
â”‚   â”œâ”€â”€ config/            # ConfiguraciÃ³n (Redis)
â”‚   â”œâ”€â”€ types/             # Interfaces y tipos
â”‚   â””â”€â”€ index.ts           # Punto de entrada
â”œâ”€â”€ .env                   # Variables de entorno
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

## ğŸš€ InstalaciÃ³n

### 1. Instalar dependencias

```bash
cd Autonomo2/ai-orchestrator
npm install
```

### 2. Configurar variables de entorno

Copiar `.env.example` a `.env` y configurar:

```env
PORT=6000
DEFAULT_LLM_PROVIDER=gemini
GEMINI_API_KEY=tu-api-key-aqui
REDIS_HOST=localhost
REDIS_PORT=6379
```

### 3. Iniciar el servidor

```bash
# Desarrollo
npm run dev

# ProducciÃ³n
npm run build
npm start
```

## ğŸ“¡ Endpoints

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| POST | `/api/chat/message` | Enviar mensaje al chatbot |
| GET | `/api/chat/history/:id` | Obtener historial de conversaciÃ³n |
| POST | `/api/chat/conversation` | Crear nueva conversaciÃ³n |
| DELETE | `/api/chat/conversation/:id` | Eliminar conversaciÃ³n |
| GET | `/api/tools` | Listar herramientas MCP disponibles |
| POST | `/api/tools/execute` | Ejecutar herramienta (testing) |
| GET | `/health` | Estado del servicio |

## ğŸ”Œ WebSocket

### Conectar al chat en tiempo real

```javascript
import { io } from 'socket.io-client';

const socket = io('http://localhost:6000');

// Enviar mensaje
socket.emit('chat:message', {
  conversationId: 'uuid',
  message: 'Hola, muÃ©strame productos',
});

// Recibir respuesta
socket.on('chat:response', (data) => {
  console.log(data);
});
```

## ğŸ› ï¸ MCP Tools (5 herramientas)

### Herramientas de Consulta (2)
1. **buscar_productos**: Busca productos en el marketplace
2. **consultar_orden**: Consulta el estado de una orden

### Herramientas de AcciÃ³n (2)
3. **crear_orden**: Crea una nueva orden de compra
4. **procesar_pago**: Procesa un pago para una orden

### Herramientas de Reporte (1)
5. **resumen_ventas**: Genera un resumen de ventas

## ğŸ§  LLM Providers Soportados

- **Google Gemini** (por defecto, gratis)
- **OpenAI GPT-4** (requiere API key de pago)
- **Claude** (prÃ³ximamente)

## ğŸ“ Ejemplo de Uso

### Enviar mensaje de texto

```bash
curl -X POST http://localhost:6000/api/chat/message \
  -H "Content-Type: application/json" \
  -d '{
    "conversationId": "uuid-123",
    "message": "MuÃ©strame los productos disponibles",
    "messageType": "text"
  }'
```

### Listar herramientas

```bash
curl http://localhost:6000/api/tools
```

## ğŸ”„ Flujo de Trabajo

1. **Usuario envÃ­a mensaje** â†’ Chat Controller
2. **Orchestrator recibe** â†’ Obtiene contexto desde Redis
3. **LLM Adapter procesa** â†’ Gemini/OpenAI genera respuesta
4. **Detecta tool call** â†’ Ejecuta herramienta MCP
5. **Obtiene resultado** â†’ Formatea respuesta
6. **Guarda contexto** â†’ Redis
7. **Responde al usuario** â†’ WebSocket/HTTP

## ğŸ” Seguridad

- IntegraciÃ³n con Auth Service para validar usuarios
- Rate limiting (prÃ³ximamente)
- ValidaciÃ³n de inputs
- SanitizaciÃ³n de respuestas

## ğŸ“¦ Dependencias Principales

- `express` - Framework HTTP
- `socket.io` - WebSocket para tiempo real
- `@google/generative-ai` - Google Gemini
- `openai` - OpenAI GPT
- `redis` - Cache de contexto
- `pdf-parse` - Procesamiento de PDFs

## ğŸ¯ Estado Actual

- âœ… Estructura base creada
- âœ… ConfiguraciÃ³n de servidor
- âœ… Redis para contexto
- âœ… Endpoints bÃ¡sicos
- âœ… WebSocket habilitado
- â³ LLM Adapters (siguiente paso)
- â³ MCP Tools (siguiente paso)
- â³ Procesamiento multimodal

## ğŸ“ Contacto

Puerto: `6000`
WebSocket: `ws://localhost:6000`
